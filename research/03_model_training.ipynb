{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Import the os module to interact with the operating system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ayupt\\\\Desktop\\\\Data Science Projects\\\\End to End Deployment\\\\Kidney-Disease-Classificaion-End-to-End-MLflow-DVC\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd  # This is a Jupyter Notebook magic command to display the current working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")  # Change the current working directory to the parent directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ayupt\\\\Desktop\\\\Data Science Projects\\\\End to End Deployment\\\\Kidney-Disease-Classificaion-End-to-End-MLflow-DVC'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd  # Again, display the updated working directory to confirm the change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from dataclasses import dataclass  # Used to define immutable (frozen) data structures\n",
    "from pathlib import Path  # Provides a convenient way to handle file system paths\n",
    "\n",
    "# Define a dataclass to store training configuration settings\n",
    "@dataclass(frozen=True)  # `frozen=True` makes the class immutable\n",
    "class TrainingConfig:\n",
    "    root_dir: Path  # Directory to store training-related artifacts\n",
    "    trained_model_path: Path  # Path to save the trained model after training\n",
    "    updated_base_model_path: Path  # Path to the updated base model file\n",
    "    training_data: Path  # Path to the dataset used for training\n",
    "    params_epochs: int  # Number of epochs for training the model\n",
    "    params_batch_size: int  # Size of each training batch\n",
    "    params_is_augmentation: bool  # Boolean flag indicating whether data augmentation is applied\n",
    "    params_image_size: list  # Dimensions of input images (e.g., [224, 224, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Importing required modules for CNN classifier setup\n",
    "'''\n",
    "\n",
    "# Importing constants (e.g., paths, hyperparameters, model configurations) from a constants module\n",
    "from cnnClassifier.constants import *\n",
    "\n",
    "# Importing utility functions for reading YAML files and creating directories\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "\n",
    "# Importing TensorFlow for deep learning model creation and training\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH):\n",
    "        \"\"\"\n",
    "        Initializes the ConfigurationManager class.\n",
    "        Reads YAML configuration and parameter files and ensures necessary directories exist.\n",
    "        \n",
    "        :param config_filepath: Path to the configuration file.\n",
    "        :param params_filepath: Path to the parameters file.\n",
    "        \"\"\"\n",
    "        self.config = read_yaml(config_filepath)  # Read and store configuration data from the YAML file\n",
    "        self.params = read_yaml(params_filepath)  # Read and store parameter values from the YAML file\n",
    "\n",
    "        # Create the root directory for storing artifacts if it does not exist\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        \"\"\"\n",
    "        Retrieves and prepares the training configuration based on the loaded configuration and parameters.\n",
    "        \n",
    "        :return: An instance of TrainingConfig containing structured training parameters.\n",
    "        \"\"\"\n",
    "        training = self.config.training  # Extract the training section from the configuration file\n",
    "        prepare_base_model = self.config.prepare_base_model  # Extract model preparation section from the config\n",
    "        params = self.params  # Extract parameters related to training\n",
    "\n",
    "        # Define the path where the training data is located\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"kidney-ct-scan-image\")\n",
    "        \n",
    "        # Ensure the root directory for training exists, creating it if necessary\n",
    "        create_directories([Path(training.root_dir)])\n",
    "\n",
    "        # Create and return a TrainingConfig object, encapsulating all necessary training parameters\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),  # Path to the training root directory\n",
    "            trained_model_path=Path(training.trained_model_path),  # Path where the trained model will be saved\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),  # Path for the updated base model\n",
    "            training_data=Path(training_data),  # Path to the training dataset\n",
    "            params_epochs=params.EPOCHS,  # Number of epochs for training\n",
    "            params_batch_size=params.BATCH_SIZE,  # Batch size for training\n",
    "            params_is_augmentation=params.AUGMENTATION,  # Boolean indicating whether data augmentation is used\n",
    "            params_image_size=params.IMAGE_SIZE  # Image size used in training\n",
    "        )\n",
    "\n",
    "        return training_config  # Return the fully configured TrainingConfig instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Provides functions for interacting with the operating system\n",
    "import urllib.request as request  # Module for fetching data across the web\n",
    "from zipfile import ZipFile  # Used for extracting zip files\n",
    "import tensorflow as tf  # TensorFlow library for machine learning and deep learning tasks\n",
    "import time  # Module for time-related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        \"\"\"\n",
    "        Initializes the Training class with configuration parameters.\n",
    "        \n",
    "        :param config: An instance of TrainingConfig containing training settings.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        \"\"\"\n",
    "        Loads the pre-trained model from the specified path.\n",
    "        \"\"\"\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "        \"\"\"\n",
    "        Prepares training and validation data generators with data augmentation.\n",
    "        \"\"\"\n",
    "        # Define standard parameters for image data generators\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale=1./255,  # Normalize pixel values\n",
    "            validation_split=0.20  # Use 20% of the data for validation\n",
    "        )\n",
    "\n",
    "        # Define parameters for resizing images and batch processing\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],  # Target image size excluding channels\n",
    "            batch_size=self.config.params_batch_size,  # Batch size for training\n",
    "            interpolation=\"bilinear\"  # Interpolation method for resizing images\n",
    "        )\n",
    "\n",
    "        # Create a validation data generator\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        # Load validation data from directory\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,  # Do not shuffle validation data\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        # Apply data augmentation if specified in configuration\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,  # Random rotation up to 40 degrees\n",
    "                horizontal_flip=True,  # Randomly flip images horizontally\n",
    "                width_shift_range=0.2,  # Random horizontal shift\n",
    "                height_shift_range=0.2,  # Random vertical shift\n",
    "                shear_range=0.2,  # Shear transformation\n",
    "                zoom_range=0.2,  # Random zoom\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator  # Use validation generator if no augmentation\n",
    "\n",
    "        # Load training data from directory\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,  # Shuffle training data\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        \"\"\"\n",
    "        Saves the trained model to the specified path.\n",
    "        \n",
    "        :param path: Path where the model will be saved.\n",
    "        :param model: Trained TensorFlow model.\n",
    "        \"\"\"\n",
    "        model.save(path)\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the model using the prepared data generators.\n",
    "        \"\"\"\n",
    "        # Calculate the number of steps per epoch for training and validation\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        # Train the model using the fit method\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,  # Number of training epochs\n",
    "            steps_per_epoch=self.steps_per_epoch,  # Steps per epoch\n",
    "            validation_steps=self.validation_steps,  # Steps per validation cycle\n",
    "            validation_data=self.valid_generator  # Validation dataset\n",
    "        )\n",
    "\n",
    "        # Save the trained model\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-15 14:53:16,618: INFO: common: YAML file: config\\config.yaml loaded successfully]\n",
      "[2025-02-15 14:53:16,642: INFO: common: YAML file: params.yaml loaded successfully]\n",
      "[2025-02-15 14:53:16,646: INFO: common: Created directory at: artifacts]\n",
      "[2025-02-15 14:53:16,649: INFO: common: Created directory at: artifacts\\training]\n",
      "Found 93 images belonging to 2 classes.\n",
      "Found 372 images belonging to 2 classes.\n",
      "23/23 [==============================] - 383s 17s/step - loss: 9.4141 - accuracy: 0.6152 - val_loss: 18.0923 - val_accuracy: 0.4750\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Initialize the configuration manager\n",
    "    config = ConfigurationManager()\n",
    "    \n",
    "    # Retrieve the training configuration settings\n",
    "    training_config = config.get_training_config()\n",
    "    \n",
    "    # Initialize the Training class with the configuration\n",
    "    training = Training(config=training_config)\n",
    "    \n",
    "    # Load the base model\n",
    "    training.get_base_model()\n",
    "    \n",
    "    # Prepare the data generators for training and validation\n",
    "    training.train_valid_generator()\n",
    "    \n",
    "    # Start the training process\n",
    "    training.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    # Raise the exception to identify and debug any errors\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kidneyproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
